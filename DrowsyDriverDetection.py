import cv2
import numpy as np
import pygame

# Define the EAR algorithm
def eye_aspect_ratio(eye):
    A = np.linalg.norm(eye[1] - eye[5])
    B = np.linalg.norm(eye[2] - eye[4])
    C = np.linalg.norm(eye[0] - eye[3])
    ear = (A + B) / (2.0 * C)
    return ear

# Load the face and eye detectors
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

# Start capturing video from the webcam
cap = cv2.VideoCapture(0)

# Set the drowsiness threshold
EAR_THRESHOLD = 0.35

# Set the parameters for face detection
face_scaleFactor = 1.3
face_minNeighbors = 5

# Set the parameters for eye detection
eye_scaleFactor = 1.1
eye_minNeighbors = 3

# Initialize Pygame
pygame.init()
pygame.mixer.music.load('alarm.wav')

frame_skip = 0
FRAME_SKIP_THRESHOLD = 2

while True:
    # Read the video feed
    ret, frame = cap.read()
    
    if frame_skip < FRAME_SKIP_THRESHOLD:
        frame_skip +=1
        continue
    else:
        frame_skip = 0

    # Convert the frame to grayscale
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect faces in the frame
    faces = face_cascade.detectMultiScale(gray, scaleFactor=face_scaleFactor, minNeighbors=face_minNeighbors)

    # Loop through each face in the frame
    for (x, y, w, h) in faces:
        # Draw a rectangle around the face
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

        # Get the ROI for the face
        roi_gray = gray[y:y + h, x:x + w]
        roi_color = frame[y:y + h, x:x + w]

        # Detect eyes in the ROI
        eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=eye_scaleFactor, minNeighbors=eye_minNeighbors)

        # Loop through each eye in the ROI
        for (ex, ey, ew, eh) in eyes:
            # Draw a rectangle around the eye
            cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (255, 0, 0), 2)

            # Calculate the EAR for the eye
            eye = roi_gray[ey:ey + eh, ex:ex + ew]
            ear = eye_aspect_ratio(eye)

            # Check if the EAR falls below the threshold
            if ear < EAR_THRESHOLD:
                # Display an alert message
                cv2.putText(frame, "DROWSINESS DETECTED!", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

                # Play an alarm sound
                pygame.mixer.music.play()

    # Display the resulting frame
    cv2.imshow('Drowsy Driver Detection', frame)

    # Exit if the 'q' key is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and close all windows
cap.release()
cv2.destroyAllWindows()
print('finish')